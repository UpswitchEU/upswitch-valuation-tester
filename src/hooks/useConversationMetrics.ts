/**
 * useConversationMetrics - Handles conversation metrics tracking
 * 
 * Extracted from StreamingChat.tsx to reduce component complexity and improve maintainability.
 * Centralizes all metrics tracking including performance monitoring and conversation analytics.
 */

import { useState, useCallback } from 'react';
import { chatLogger } from '../utils/logger';
import { ConversationMetrics } from './useStreamingChatState';

// Re-export types for convenience
export interface ModelPerformanceMetrics {
  model_name: string;
  model_version: string;
  time_to_first_token_ms: number;
  total_response_time_ms: number;
  tokens_per_second: number;
  response_coherence_score?: number;
  response_relevance_score?: number;
  hallucination_detected: boolean;
  input_tokens: number;
  output_tokens: number;
  estimated_cost_usd: number;
  error_occurred: boolean;
  error_type?: string;
  retry_count: number;
}

/**
 * Custom hook that manages conversation metrics and performance tracking
 * 
 * @param sessionId - Unique session identifier
 * @param userId - Optional user identifier
 * @returns Metrics state and tracking functions
 */
export const useConversationMetrics = (sessionId: string, userId?: string) => {
  const [metrics, setMetrics] = useState<ConversationMetrics>({
    session_id: sessionId,
    user_id: userId,
    started_at: new Date(),
    total_turns: 0,
    successful: false,
    ai_response_count: 0,
    user_message_count: 0,
    error_count: 0,
    retry_count: 0,
    avg_response_time_ms: 0,
    valuation_generated: false,
    data_completeness_percent: 0,
    collected_fields: [],
    total_tokens_used: 0,
    estimated_cost_usd: 0,
    feedback_provided: false
  });

  /**
   * Track model performance metrics
   */
  const trackModelPerformance = useCallback((performanceMetrics: ModelPerformanceMetrics) => {
    chatLogger.info('Model performance tracked', {
      sessionId,
      model: performanceMetrics.model_name,
      responseTime: performanceMetrics.total_response_time_ms,
      tokens: performanceMetrics.output_tokens,
      cost: performanceMetrics.estimated_cost_usd
    });

    // Update conversation metrics with model performance
    setMetrics(prev => ({
      ...prev,
      total_tokens_used: prev.total_tokens_used + performanceMetrics.output_tokens,
      estimated_cost_usd: prev.estimated_cost_usd + performanceMetrics.estimated_cost_usd,
      avg_response_time_ms: prev.avg_response_time_ms === 0 
        ? performanceMetrics.total_response_time_ms 
        : (prev.avg_response_time_ms + performanceMetrics.total_response_time_ms) / 2
    }));

    // Log performance warnings
    if (performanceMetrics.total_response_time_ms > 5000) {
      chatLogger.warn('Slow model response detected', {
        sessionId,
        responseTime: performanceMetrics.total_response_time_ms,
        threshold: 5000
      });
    }

    if (performanceMetrics.estimated_cost_usd > 0.10) { // Alert if cost > $0.10
      chatLogger.warn('High cost response detected', {
        sessionId,
        cost: performanceMetrics.estimated_cost_usd,
        tokens: performanceMetrics.output_tokens
      });
    }
  }, [sessionId]);

  /**
   * Track conversation completion
   */
  const trackConversationCompletion = useCallback((success: boolean, hasValuation: boolean) => {
    chatLogger.info('Conversation completion tracked', {
      sessionId,
      success,
      hasValuation,
      totalTurns: metrics.total_turns
    });

    setMetrics(prev => ({
      ...prev,
      successful: success,
      valuation_generated: hasValuation
    }));

    // Track completion analytics
    chatLogger.info('conversation_completed', {
      session_id: sessionId,
      user_id: userId,
      success,
      has_valuation: hasValuation,
      total_turns: metrics.total_turns,
      ai_responses: metrics.ai_response_count,
      user_messages: metrics.user_message_count,
      errors: metrics.error_count,
      retries: metrics.retry_count,
      avg_response_time_ms: metrics.avg_response_time_ms,
      total_tokens: metrics.total_tokens_used,
      estimated_cost_usd: metrics.estimated_cost_usd,
      data_completeness_percent: metrics.data_completeness_percent,
      collected_fields: metrics.collected_fields
    });
  }, [sessionId, userId, metrics]);

  /**
   * Update metrics with partial data
   */
  const updateMetrics = useCallback((updates: Partial<ConversationMetrics>) => {
    setMetrics(prev => ({ ...prev, ...updates }));
    
    chatLogger.debug('Metrics updated', {
      sessionId,
      updates: Object.keys(updates)
    });
  }, [sessionId]);

  /**
   * Increment turn count
   */
  const incrementTurn = useCallback(() => {
    setMetrics(prev => ({
      ...prev,
      total_turns: prev.total_turns + 1
    }));
  }, []);

  /**
   * Increment AI response count
   */
  const incrementAIResponse = useCallback(() => {
    setMetrics(prev => ({
      ...prev,
      ai_response_count: prev.ai_response_count + 1
    }));
  }, []);

  /**
   * Increment user message count
   */
  const incrementUserMessage = useCallback(() => {
    setMetrics(prev => ({
      ...prev,
      user_message_count: prev.user_message_count + 1
    }));
  }, []);

  /**
   * Increment error count
   */
  const incrementError = useCallback(() => {
    setMetrics(prev => ({
      ...prev,
      error_count: prev.error_count + 1
    }));
  }, []);

  /**
   * Increment retry count
   */
  const incrementRetry = useCallback(() => {
    setMetrics(prev => ({
      ...prev,
      retry_count: prev.retry_count + 1
    }));
  }, []);

  /**
   * Update data completeness
   */
  const updateDataCompleteness = useCallback((completeness: number, collectedFields: string[]) => {
    setMetrics(prev => ({
      ...prev,
      data_completeness_percent: completeness,
      collected_fields: collectedFields
    }));
  }, []);

  /**
   * Mark feedback as provided
   */
  const markFeedbackProvided = useCallback(() => {
    setMetrics(prev => ({
      ...prev,
      feedback_provided: true
    }));
  }, []);

  /**
   * Reset metrics (useful for testing or new conversation)
   */
  const resetMetrics = useCallback(() => {
    setMetrics({
      session_id: sessionId,
      user_id: userId,
      started_at: new Date(),
      total_turns: 0,
      successful: false,
      ai_response_count: 0,
      user_message_count: 0,
      error_count: 0,
      retry_count: 0,
      avg_response_time_ms: 0,
      valuation_generated: false,
      data_completeness_percent: 0,
      collected_fields: [],
      total_tokens_used: 0,
      estimated_cost_usd: 0,
      feedback_provided: false
    });
  }, [sessionId, userId]);

  /**
   * Get metrics summary for logging
   */
  const getMetricsSummary = useCallback(() => {
    return {
      sessionId,
      userId,
      duration: Date.now() - metrics.started_at.getTime(),
      totalTurns: metrics.total_turns,
      success: metrics.successful,
      aiResponses: metrics.ai_response_count,
      userMessages: metrics.user_message_count,
      errors: metrics.error_count,
      retries: metrics.retry_count,
      avgResponseTime: metrics.avg_response_time_ms,
      valuationGenerated: metrics.valuation_generated,
      dataCompleteness: metrics.data_completeness_percent,
      collectedFields: metrics.collected_fields.length,
      totalTokens: metrics.total_tokens_used,
      estimatedCost: metrics.estimated_cost_usd,
      feedbackProvided: metrics.feedback_provided
    };
  }, [sessionId, userId, metrics]);

  return {
    metrics,
    trackModelPerformance,
    trackConversationCompletion,
    updateMetrics,
    incrementTurn,
    incrementAIResponse,
    incrementUserMessage,
    incrementError,
    incrementRetry,
    updateDataCompleteness,
    markFeedbackProvided,
    resetMetrics,
    getMetricsSummary
  };
};

